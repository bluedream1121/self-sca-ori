{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify whether image directory exists and the form is the correct form.\n",
    "\n",
    "per_image = 468\n",
    "dataset_path = \"../../data\"\n",
    "assert os.path.exists(os.path.join(dataset_path, \"patchPoseA\"))\n",
    "assert os.path.exists(os.path.join(dataset_path, \"patchPoseB\"))\n",
    "print(os.listdir(os.path.join(dataset_path, \"patchPoseA\"))[0])\n",
    "print(os.listdir(os.path.join(dataset_path, \"patchPoseB\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatchPoseA, PatchPoseB, data number verification\n",
    "# The number of whole images in the data directory must be divisible to the patches extracted per image. \n",
    "\n",
    "\n",
    "print(len(os.listdir(os.path.join(dataset_path, \"patchPoseA\"))))\n",
    "print(len(os.listdir(os.path.join(dataset_path, \"patchPoseB\"))))\n",
    "\n",
    "assert len(os.listdir(os.path.join(dataset_path, \"patchPoseA\"))) % per_image == 0\n",
    "assert len(os.listdir(os.path.join(dataset_path, \"patchPoseB\"))) % per_image == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You could change the idx to observe images\n",
    "idx_to_observe = 0\n",
    "\n",
    "lines = open(os.path.join(dataset_path, \"patchPoseA.txt\")).readlines()\n",
    "fig, axs = plt.subplots(6, 6, figsize=(20, 20))\n",
    "for i in range(per_image // 13):\n",
    "    image = Image.open(os.path.join(dataset_path, lines[13 * i + 468 * idx_to_observe].split(' ')[1]))\n",
    "    axs[i // 6, i % 6].imshow(image)\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 13, figsize=(20, 20))\n",
    "for i in range(per_image // 36):\n",
    "    image = Image.open(os.path.join(dataset_path, lines[i + 468 * idx_to_observe].split(' ')[1]))\n",
    "    axs[i].imshow(image)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check train: val: test\n",
    "patchPoseA_list_dir = os.path.join(dataset_path, \"patchPoseAImageList\")\n",
    "patchPoseB_list_dir = os.path.join(dataset_path, \"patchPoseAImageList\")\n",
    "\n",
    "assert os.path.exists(patchPoseA_list_dir)\n",
    "assert os.path.exists(patchPoseB_list_dir)\n",
    "\n",
    "trainAfp, valAfp, testAfp = (\n",
    "    open(os.path.join(patchPoseA_list_dir, \"train_acquired.txt\")), \n",
    "    open(os.path.join(patchPoseA_list_dir, \"val_acquired.txt\")), \n",
    "    open(os.path.join(patchPoseA_list_dir, \"test_acquired.txt\")),\n",
    ")\n",
    "\n",
    "trainA, valA, testA = (\n",
    "    trainAfp.readlines(), \n",
    "    valAfp.readlines(),\n",
    "    testAfp.readlines(),\n",
    ")\n",
    "\n",
    "trainBfp, valBfp, testBfp = (\n",
    "    open(os.path.join(patchPoseB_list_dir, \"train_acquired.txt\")),\n",
    "    open(os.path.join(patchPoseB_list_dir, \"val_acquired.txt\")), \n",
    "    open(os.path.join(patchPoseB_list_dir, \"test_acquired.txt\")),\n",
    ")\n",
    "\n",
    "trainB, valB, testB = (\n",
    "    trainBfp.readlines(), \n",
    "    valBfp.readlines(),\n",
    "    testBfp.readlines(),\n",
    ")\n",
    "\n",
    "allA = len(trainA) + len(valA) + len(testA)\n",
    "allB = len(trainB) + len(valB) + len(testB)\n",
    "\n",
    "print(f\"train: val: test = {len(trainA) / allA} : {len(valA) / allA} : {len(testA) / allA}\")\n",
    "print(f\"train: val: test = {len(trainB) / allB} : {len(valB) / allB} : {len(testB) / allB}\")\n",
    "\n",
    "trainAfp.close(); valAfp.close(); testAfp.close(); \n",
    "trainBfp.close(); valBfp.close(); testBfp.close(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could change the idx to observe images\n",
    "idx_to_observe = 2\n",
    "\n",
    "lines = open(os.path.join(patchPoseA_list_dir, \"train_acquired.txt\")).readlines()\n",
    "print(len(lines))\n",
    "fig, axs = plt.subplots(5, 10, figsize=(120, 60))\n",
    "for i in range(50):\n",
    "    image = Image.open(os.path.join(dataset_path, lines[468 * i].rstrip(\"\\n\")))\n",
    "    axs[i // 10, i % 10].imshow(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could change the idx to observe images\n",
    "\n",
    "lines = open(os.path.join(patchPoseA_list_dir, \"train_pruned.txt\")).readlines()\n",
    "fig, axs = plt.subplots(5, 10, figsize=(120, 60))\n",
    "for i in range(50):\n",
    "    image = Image.open(os.path.join(dataset_path, lines[468 * i].rstrip(\"\\n\")))\n",
    "    axs[i // 10, i % 10].imshow(image)\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Performance\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "path = \"/user4/yoonwoo/output_sift/output_feat.txt.result.npz\"\n",
    "npz_file = np.load(path, allow_pickle=True)\n",
    "thresholds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_separate, sca_separate, both_separate = {}, {}, {}\n",
    "for angle in range(0, 360, 10):\n",
    "    angle_separate[angle] = []\n",
    "for scale in [round(2 ** ((i - 6) / 3), 4) for i in range(13)]:\n",
    "    sca_separate[scale] = []\n",
    "for angle in range(0, 360, 10): \n",
    "    for scale in [round(2 ** ((i - 6) / 3), 4) for i in range(13)]:\n",
    "        both_separate[(angle, scale)] = []\n",
    "        \n",
    "for key,val in tqdm.tqdm(npz_file.items()):\n",
    "    ori = int(key.split(\"/\")[-1].split(\"_\")[0])\n",
    "    sca = float(key.split(\"/\")[-1].split(\"_\")[1][:-len(\".ppm\")])\n",
    "    score = (val < thresholds).astype(float).mean()\n",
    "    sca_separate[sca].append(score)\n",
    "    angle_separate[ori].append(score)\n",
    "    both_separate[(ori, sca)].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_mean = {k: np.mean(v) for (k,v) in angle_separate.items()}\n",
    "sca_mean = {k: np.mean(v) for (k,v) in sca_separate.items()}\n",
    "both_mean = {k: np.mean(v) for (k,v) in both_separate.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_list = np.array(list(angle_mean.values())).reshape(1, -1)\n",
    "sca_list = np.array(list(sca_mean.values())).reshape(1, -1)\n",
    "both_list = np.array(list(both_mean.values())).reshape(36, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "angle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Accuracy Color Map\n",
    "fig, ax = plt.subplots(figsize=(40,6))\n",
    "im = ax.imshow(angle_list, cmap=\"Blues\")\n",
    "ax.set_xticks(np.arange(36))\n",
    "ax.set_yticks(np.arange(1))\n",
    "ax.set_xticklabels(list(map(str, range(0, 360, 10))))\n",
    "for i in range(36):\n",
    "    ax.text(i, 0, round(angle_list[0][i], 4), ha=\"center\", va=\"center\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Accuracy Color Map\n",
    "fig, ax = plt.subplots(figsize=(40,6))\n",
    "im = ax.imshow(sca_list, cmap=\"Blues\")\n",
    "ax.set_xticks(np.arange(13))\n",
    "ax.set_yticks(np.arange(1))\n",
    "ax.set_xticklabels(list(map(str, [round(2 ** ((i - 6) / 3), 4) for i in range(13)])))\n",
    "for i in range(13):\n",
    "    ax.text(i, 0, round(sca_list[0][i], 4), ha=\"center\", va=\"center\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Accuracy Color Map\n",
    "fig, ax = plt.subplots(figsize=(40,50))\n",
    "im = ax.imshow(both_list, cmap=\"Blues\")\n",
    "ax.set_yticks(np.arange(36))\n",
    "ax.set_xticks(np.arange(13))\n",
    "ax.set_yticklabels(range(0, 360, 10))\n",
    "ax.set_xticklabels(list(map(str, [round(2 ** ((i - 6) / 3), 4) for i in range(13)])))\n",
    "for i in range(36):\n",
    "    for j in range(13):\n",
    "        ax.text(j, i, round(both_list[i][j], 4), ha=\"center\", va=\"center\", color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('lfnet': conda)",
   "language": "python",
   "name": "python38564bitlfnetconda4ff9592734cf4855b0a807ac88c2f442"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
